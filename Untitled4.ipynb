{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":100568,"status":"ok","timestamp":1653972387620,"user":{"displayName":"AkshatMishra 8b","userId":"06957764331805946181"},"user_tz":-330},"id":"KzsiN3l_Vy1p","outputId":"53e17e1c-cc0a-42b6-a9e9-6837f60bbedb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.2.0+cu92\n","  Downloading https://download.pytorch.org/whl/cu92/torch-1.2.0%2Bcu92-cp37-cp37m-manylinux1_x86_64.whl (663.1 MB)\n","\u001b[K     |████████████████████████████████| 663.1 MB 1.7 kB/s \n","\u001b[?25hCollecting torchvision==0.4.0+cu92\n","  Downloading https://download.pytorch.org/whl/cu92/torchvision-0.4.0%2Bcu92-cp37-cp37m-manylinux1_x86_64.whl (8.8 MB)\n","\u001b[K     |████████████████████████████████| 8.8 MB 38.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.2.0+cu92) (1.21.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0+cu92) (1.15.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0+cu92) (7.1.2)\n","Installing collected packages: torch, torchvision\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.11.0+cu113\n","    Uninstalling torch-1.11.0+cu113:\n","      Successfully uninstalled torch-1.11.0+cu113\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.12.0+cu113\n","    Uninstalling torchvision-0.12.0+cu113:\n","      Successfully uninstalled torchvision-0.12.0+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.2.0+cu92 which is incompatible.\n","torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.2.0+cu92 which is incompatible.\u001b[0m\n","Successfully installed torch-1.2.0+cu92 torchvision-0.4.0+cu92\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["torch"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"lLyw9p05cgKD","executionInfo":{"status":"ok","timestamp":1653986874885,"user_tz":-330,"elapsed":4,"user":{"displayName":"AkshatMishra 8b","userId":"06957764331805946181"}}},"outputs":[],"source":["import nltk"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1691,"status":"ok","timestamp":1653986880044,"user":{"displayName":"AkshatMishra 8b","userId":"06957764331805946181"},"user_tz":-330},"id":"ADJcgMpJclOT","outputId":"1cc215d1-bf9a-4eb1-a4f9-6b39012f493c"},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}],"source":["\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4337,"status":"ok","timestamp":1653986887974,"user":{"displayName":"AkshatMishra 8b","userId":"06957764331805946181"},"user_tz":-330},"id":"MYmfq-SY_yQs","outputId":"79688900-c09f-419f-d2a1-d3e527e82dc6"},"outputs":[{"output_type":"stream","name":"stdout","text":["26 patterns\n","7 tags: ['delivery', 'funny', 'goodbye', 'greeting', 'items', 'payments', 'thanks']\n","54 unique stemmed words: [\"'s\", 'a', 'accept', 'anyon', 'are', 'bye', 'can', 'card', 'cash', 'credit', 'day', 'deliveri', 'do', 'doe', 'funni', 'get', 'good', 'goodby', 'have', 'hello', 'help', 'hey', 'hi', 'how', 'i', 'is', 'item', 'joke', 'kind', 'know', 'later', 'long', 'lot', 'mastercard', 'me', 'my', 'of', 'onli', 'pay', 'paypal', 'see', 'sell', 'ship', 'someth', 'take', 'tell', 'thank', 'that', 'there', 'what', 'when', 'which', 'with', 'you']\n","54 7\n","Epoch [100/1000], Loss: 1.4433\n","Epoch [200/1000], Loss: 0.1334\n","Epoch [300/1000], Loss: 0.0197\n","Epoch [400/1000], Loss: 0.0058\n","Epoch [500/1000], Loss: 0.0040\n","Epoch [600/1000], Loss: 0.0020\n","Epoch [700/1000], Loss: 0.0023\n","Epoch [800/1000], Loss: 0.0023\n","Epoch [900/1000], Loss: 0.0015\n","Epoch [1000/1000], Loss: 0.0004\n","final loss: 0.0004\n","training complete. file saved to data.pth\n"]}],"source":["import numpy as np\n","import random\n","import json\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","from nltk_utils import bag_of_words, tokenize, stem\n","from model import NeuralNet\n","\n","with open('intents.json', 'r') as f:\n","    intents = json.load(f)\n","\n","all_words = []\n","tags = []\n","xy = []\n","# loop through each sentence in our intents patterns\n","for intent in intents['intents']:\n","    tag = intent['tag']\n","    # add to tag list\n","    tags.append(tag)\n","    for pattern in intent['patterns']:\n","        # tokenize each word in the sentence\n","        w = tokenize(pattern)\n","        # add to our words list\n","        all_words.extend(w)\n","        # add to xy pair\n","        xy.append((w, tag))\n","\n","# stem and lower each word\n","ignore_words = ['?', '.', '!']\n","all_words = [stem(w) for w in all_words if w not in ignore_words]\n","# remove duplicates and sort\n","all_words = sorted(set(all_words))\n","tags = sorted(set(tags))\n","\n","print(len(xy), \"patterns\")\n","print(len(tags), \"tags:\", tags)\n","print(len(all_words), \"unique stemmed words:\", all_words)\n","\n","# create training data\n","X_train = []\n","y_train = []\n","for (pattern_sentence, tag) in xy:\n","    # X: bag of words for each pattern_sentence\n","    bag = bag_of_words(pattern_sentence, all_words)\n","    X_train.append(bag)\n","    # y: PyTorch CrossEntropyLoss needs only class labels, not one-hot\n","    label = tags.index(tag)\n","    y_train.append(label)\n","\n","X_train = np.array(X_train)\n","y_train = np.array(y_train)\n","\n","# Hyper-parameters \n","num_epochs = 1000\n","batch_size = 8\n","learning_rate = 0.001\n","input_size = len(X_train[0])\n","hidden_size = 8\n","output_size = len(tags)\n","print(input_size, output_size)\n","\n","class ChatDataset(Dataset):\n","\n","    def __init__(self):\n","        self.n_samples = len(X_train)\n","        self.x_data = X_train\n","        self.y_data = y_train\n","\n","    # support indexing such that dataset[i] can be used to get i-th sample\n","    def __getitem__(self, index):\n","        return self.x_data[index], self.y_data[index]\n","\n","    # we can call len(dataset) to return the size\n","    def __len__(self):\n","        return self.n_samples\n","\n","dataset = ChatDataset()\n","train_loader = DataLoader(dataset=dataset,\n","                          batch_size=batch_size,\n","                          shuffle=True,\n","                          num_workers=0)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = NeuralNet(input_size, hidden_size, output_size).to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Train the model\n","for epoch in range(num_epochs):\n","    for (words, labels) in train_loader:\n","        words = words.to(device)\n","        labels = labels.to(dtype=torch.long).to(device)\n","        \n","        # Forward pass\n","        outputs = model(words)\n","        # if y would be one-hot, we must apply\n","        # labels = torch.max(labels, 1)[1]\n","        loss = criterion(outputs, labels)\n","        \n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","    if (epoch+1) % 100 == 0:\n","        print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n","\n","\n","print(f'final loss: {loss.item():.4f}')\n","\n","data = {\n","\"model_state\": model.state_dict(),\n","\"input_size\": input_size,\n","\"hidden_size\": hidden_size,\n","\"output_size\": output_size,\n","\"all_words\": all_words,\n","\"tags\": tags\n","}\n","\n","FILE = \"data.pth\"\n","torch.save(data, FILE)\n","\n","print(f'training complete. file saved to {FILE}')"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jh7idAuYCGtv","outputId":"7946dba4-15dd-4509-f226-70e6bf9e94e1","executionInfo":{"status":"ok","timestamp":1653986984925,"user_tz":-330,"elapsed":88627,"user":{"displayName":"AkshatMishra 8b","userId":"06957764331805946181"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Let's chat! (type 'quit' to exit)\n","You: hi what up\n","Sam: Hey :-)\n","You: great\n","Sam: I do not understand...\n","You: what do you sell\n","Sam: We sell coffee and tea\n","You: who created you\n","Sam: I do not understand...\n","You: quit\n"]}],"source":["import random\n","import json\n","\n","import torch\n","\n","from model import NeuralNet\n","from nltk_utils import bag_of_words, tokenize\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","with open('intents.json', 'r') as json_data:\n","    intents = json.load(json_data)\n","\n","FILE = \"data.pth\"\n","data = torch.load(FILE)\n","\n","input_size = data[\"input_size\"]\n","hidden_size = data[\"hidden_size\"]\n","output_size = data[\"output_size\"]\n","all_words = data['all_words']\n","tags = data['tags']\n","model_state = data[\"model_state\"]\n","\n","model = NeuralNet(input_size, hidden_size, output_size).to(device)\n","model.load_state_dict(model_state)\n","model.eval()\n","\n","bot_name = \"Ak\n","print(\"Let's chat! (type 'quit' to exit)\")\n","while True:\n","    # sentence = \"do you use credit cards?\"\n","    sentence = input(\"You: \")\n","    if sentence == \"quit\":\n","        break\n","\n","    sentence = tokenize(sentence)\n","    X = bag_of_words(sentence, all_words)\n","    X = X.reshape(1, X.shape[0])\n","    X = torch.from_numpy(X).to(device)\n","\n","    output = model(X)\n","    _, predicted = torch.max(output, dim=1)\n","\n","    tag = tags[predicted.item()]\n","\n","    probs = torch.softmax(output, dim=1)\n","    prob = probs[0][predicted.item()]\n","    if prob.item() > 0.75:\n","        for intent in intents['intents']:\n","            if tag == intent[\"tag\"]:\n","                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n","    else:\n","        print(f\"{bot_name}: I do not understand...\")"]}],"metadata":{"colab":{"name":"Untitled4.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}